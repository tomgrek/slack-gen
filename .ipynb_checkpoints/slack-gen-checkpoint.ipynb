{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./slack.parsed') as s:\n",
    "    c = s.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "speaker_re = re.compile('<__(\\S+)__>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [(z.start(), z.group()) for z in re.finditer(speaker_re, c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "speakers = defaultdict(int)\n",
    "for speaker in pos:\n",
    "    speakers[speaker[1]] += 1\n",
    "unique_speakers = list(speakers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_speaker(char_pos):\n",
    "    for i, item in enumerate(pos):\n",
    "        if i + 1 >= len(pos): return 0\n",
    "        if char_pos >= item[0] and char_pos < pos[i+1][0]:\n",
    "            try:\n",
    "                return unique_speakers.index(item[1])\n",
    "            except:\n",
    "                return 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import torch.utils.data\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlackModel(nn.Module):\n",
    "    def __init__(self, batch_size, input_size, hidden_size, output_size, embedding_size=20, speaker_embedding_size=4, n_layers=1, n_speakers=1):\n",
    "        super(SlackModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
    "        self.speaker_encoder = nn.Embedding(n_speakers, speaker_embedding_size)\n",
    "        self.hidden = nn.Linear(embedding_size+speaker_embedding_size, hidden_size) #input size is hidden size\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers) #input size, hidden size\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.speaker_embedding_size = speaker_embedding_size\n",
    "\n",
    "    def forward(self, input, speaker, hidden):\n",
    "        batch_size = input.size(0) #better than hardcoding it -> later we can generate text with batch size 1\n",
    "        encoded = self.encoder(input)\n",
    "        speaker_encoded = self.speaker_encoder(speaker)\n",
    "        both = torch.cat((encoded, speaker_encoded), dim=1)\n",
    "        \n",
    "        hidden_i = self.hidden(both.view(-1, self.embedding_size+self.speaker_embedding_size))\n",
    "\n",
    "        linear = F.relu(hidden_i)\n",
    "        \n",
    "        lin_out = linear.view(1, batch_size, -1)\n",
    "        \n",
    "        output, hidden = self.rnn(lin_out, hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_longtensor(chunk):\n",
    "    tensor = torch.zeros(len(chunk)).long()\n",
    "    for i in range(len(chunk)):\n",
    "        try:\n",
    "            tensor[i] = all_characters.index(chunk[i])\n",
    "        except:\n",
    "            continue # strange unicodes - we had Hebrew, Chinese, bullet points ...\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "\n",
    "n_epochs = 200\n",
    "chunk_len = 288\n",
    "batch_size = 96\n",
    "input_len = len(convs)\n",
    "embedding_size = 20\n",
    "speaker_embedding_size = 4\n",
    "n_layers = 2\n",
    "n_speakers = len(unique_speakers)\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "hidden_size = 142\n",
    "\n",
    "def get_training_batch(chunk_len, batch_size):\n",
    "    inp = torch.LongTensor(batch_size, chunk_len)\n",
    "    spkr = torch.LongTensor(batch_size, chunk_len)\n",
    "    target = torch.LongTensor(batch_size, chunk_len)\n",
    "    for bi in range(batch_size):\n",
    "        start_index = random.randint(0, input_len - chunk_len)\n",
    "        speaker = find_speaker(start_index)\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        chunk = convs[start_index:end_index]\n",
    "        inp[bi] = string_to_longtensor(chunk[:-1])\n",
    "        spkr[bi] = speaker\n",
    "        target[bi] = string_to_longtensor(chunk[1:])\n",
    "    inp = Variable(inp)\n",
    "    target = Variable(target)\n",
    "    spkr = Variable(spkr)\n",
    "    if cuda:\n",
    "        inp = inp.cuda()\n",
    "        target = target.cuda()\n",
    "        spkr = spkr.cuda()\n",
    "    return inp, spkr, target\n",
    "\n",
    "def train(inp, speaker, target):\n",
    "    hidden = m.init_hidden(batch_size)\n",
    "    if cuda:\n",
    "        hidden = hidden.cuda()\n",
    "    m.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        t = inp[:, c]\n",
    "        sp = speaker[:, c]\n",
    "        output, hidden = m(t, sp, hidden)\n",
    "        loss += criterion(output.view(batch_size, -1), target[:,c])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.data[0] / chunk_len\n",
    "\n",
    "def save():\n",
    "    save_filename = '{}.pt'.format('slack.model')\n",
    "    torch.save(m, save_filename)\n",
    "    print('Saved as {}'.format(save_filename))\n",
    "\n",
    "m = SlackModel(\n",
    "    batch_size,\n",
    "    n_characters,\n",
    "    hidden_size,\n",
    "    n_characters,\n",
    "    n_layers=n_layers,\n",
    "    embedding_size=embedding_size,\n",
    "    speaker_embedding_size=speaker_embedding_size,\n",
    "    n_speakers=n_speakers\n",
    ")\n",
    "\n",
    "if cuda:\n",
    "    m.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "n_epochs = 1800\n",
    "\n",
    "for epoch in tqdm(range(0, n_epochs)):\n",
    "    loss = train(*get_training_batch(chunk_len, batch_size))\n",
    "    if epoch % 20 == 0:\n",
    "        print('(Epoch {} of {}) - {}'.format(epoch, n_epochs, loss))\n",
    "        print(generate('?', 100), '\\n')\n",
    "\n",
    "print(\"Saving...\")\n",
    "save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_num(spkr):\n",
    "    try:\n",
    "        return unique_speakers.index(spkr)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def generate(prime_str='A', prime_speaker='<__tom_grek__>', predict_len=100, temperature=0.7):\n",
    "    hidden = m.init_hidden(batch_size=1)\n",
    "    prime_input = Variable(string_to_longtensor(prime_str))\n",
    "    prime_speaker = Variable(torch.LongTensor([get_speaker_num(prime_speaker)]))\n",
    "    if cuda:\n",
    "        hidden = hidden.cuda()\n",
    "        prime_input = prime_input.cuda()\n",
    "        prime_speaker = prime_speaker.cuda()\n",
    "    predicted = prime_str\n",
    "\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = m(prime_input[p].view(1), prime_speaker, hidden)\n",
    "        \n",
    "    inp = prime_input[-1].view(1)\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = m(inp.view(1), prime_speaker, hidden)\n",
    "        \n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        # divide output tensor by temperature, e^x (so positive)\n",
    "        # then pytorch provides a nice way to pick the most likely num_samples from that,\n",
    "        # modelling the above as a multinomial distribution ie weights (likeliness\n",
    "        # to be picked), or probabilities\n",
    "        most_likely = torch.multinomial(output_dist, num_samples=1)[0]\n",
    "\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[most_likely]\n",
    "        predicted += predicted_char\n",
    "        inp = Variable(string_to_longtensor(predicted_char))\n",
    "        if cuda:\n",
    "            inp = inp.cuda()\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we should a learn to we will going in this last the look a lecial the about the use as for the sent the meting\n"
     ]
    }
   ],
   "source": [
    "print(generate(prime_str='we should ', prime_speaker='<__tom_grek__>', temperature=0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
